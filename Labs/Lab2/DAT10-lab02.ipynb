{
 "metadata": {
  "name": "",
  "signature": "sha256:84c6d7163071a3f4f82e91f7aa78623d59f0800391c45c80033fbf1b33c958d1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# GA Data Science 10 (DAT5) - Lab2\n",
      "\n",
      "### Importing Data - JSON, CSVs, APIs\n",
      "\n",
      "Craig Sakuma\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Last time we covered introductions to: \n",
      "- #### Python \n",
      "- #### iPython Notebooks\n",
      "- #### numpy  \n",
      "- #### Pandas\n",
      "\n",
      "#### Questions?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Agenda\n",
      "\n",
      "1. JSON\n",
      "2. API "
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "1. JSON"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "- What's Json? (and why do we care?)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# load the homework data into a pandas dataset\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "data = pd.read_csv(\"titanic-train.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# assign the first 5 rows to a variable called first\n",
      "\n",
      "first = data.head(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "first"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>PassengerId</th>\n",
        "      <th>Survived</th>\n",
        "      <th>Pclass</th>\n",
        "      <th>Name</th>\n",
        "      <th>Sex</th>\n",
        "      <th>Age</th>\n",
        "      <th>SibSp</th>\n",
        "      <th>Parch</th>\n",
        "      <th>Ticket</th>\n",
        "      <th>Fare</th>\n",
        "      <th>Cabin</th>\n",
        "      <th>Embarked</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                           Braund, Mr. Owen Harris</td>\n",
        "      <td>   male</td>\n",
        "      <td> 22</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>        A/5 21171</td>\n",
        "      <td>  7.2500</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
        "      <td> female</td>\n",
        "      <td> 38</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>         PC 17599</td>\n",
        "      <td> 71.2833</td>\n",
        "      <td>  C85</td>\n",
        "      <td> C</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 3</td>\n",
        "      <td>                            Heikkinen, Miss. Laina</td>\n",
        "      <td> female</td>\n",
        "      <td> 26</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> STON/O2. 3101282</td>\n",
        "      <td>  7.9250</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 4</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td>      Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
        "      <td> female</td>\n",
        "      <td> 35</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td>           113803</td>\n",
        "      <td> 53.1000</td>\n",
        "      <td> C123</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 5</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td>                          Allen, Mr. William Henry</td>\n",
        "      <td>   male</td>\n",
        "      <td> 35</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td>           373450</td>\n",
        "      <td>  8.0500</td>\n",
        "      <td>  NaN</td>\n",
        "      <td> S</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "   PassengerId  Survived  Pclass  \\\n",
        "0            1         0       3   \n",
        "1            2         1       1   \n",
        "2            3         1       3   \n",
        "3            4         1       1   \n",
        "4            5         0       3   \n",
        "\n",
        "                                                Name     Sex  Age  SibSp  \\\n",
        "0                            Braund, Mr. Owen Harris    male   22      1   \n",
        "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
        "2                             Heikkinen, Miss. Laina  female   26      0   \n",
        "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
        "4                           Allen, Mr. William Henry    male   35      0   \n",
        "\n",
        "   Parch            Ticket     Fare Cabin Embarked  \n",
        "0      0         A/5 21171   7.2500   NaN        S  \n",
        "1      0          PC 17599  71.2833   C85        C  \n",
        "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
        "3      0            113803  53.1000  C123        S  \n",
        "4      0            373450   8.0500   NaN        S  "
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# use the DataFrame method to_json to transform <first> into a json object\n",
      "first.to_json()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "'{\"PassengerId\":{\"0\":1,\"1\":2,\"2\":3,\"3\":4,\"4\":5},\"Survived\":{\"0\":0,\"1\":1,\"2\":1,\"3\":1,\"4\":0},\"Pclass\":{\"0\":3,\"1\":1,\"2\":3,\"3\":1,\"4\":3},\"Name\":{\"0\":\"Braund, Mr. Owen Harris\",\"1\":\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",\"2\":\"Heikkinen, Miss. Laina\",\"3\":\"Futrelle, Mrs. Jacques Heath (Lily May Peel)\",\"4\":\"Allen, Mr. William Henry\"},\"Sex\":{\"0\":\"male\",\"1\":\"female\",\"2\":\"female\",\"3\":\"female\",\"4\":\"male\"},\"Age\":{\"0\":22.0,\"1\":38.0,\"2\":26.0,\"3\":35.0,\"4\":35.0},\"SibSp\":{\"0\":1,\"1\":1,\"2\":0,\"3\":1,\"4\":0},\"Parch\":{\"0\":0,\"1\":0,\"2\":0,\"3\":0,\"4\":0},\"Ticket\":{\"0\":\"A\\\\/5 21171\",\"1\":\"PC 17599\",\"2\":\"STON\\\\/O2. 3101282\",\"3\":\"113803\",\"4\":\"373450\"},\"Fare\":{\"0\":7.25,\"1\":71.2833,\"2\":7.925,\"3\":53.1,\"4\":8.05},\"Cabin\":{\"0\":null,\"1\":\"C85\",\"2\":null,\"3\":\"C123\",\"4\":null},\"Embarked\":{\"0\":\"S\",\"1\":\"C\",\"2\":\"S\",\"3\":\"S\",\"4\":\"S\"}}'"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# explore the different options in the to_json method\n",
      "first.to_json(orient = 'records')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "'[{\"PassengerId\":1,\"Survived\":0,\"Pclass\":3,\"Name\":\"Braund, Mr. Owen Harris\",\"Sex\":\"male\",\"Age\":22.0,\"SibSp\":1,\"Parch\":0,\"Ticket\":\"A\\\\/5 21171\",\"Fare\":7.25,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":2,\"Survived\":1,\"Pclass\":1,\"Name\":\"Cumings, Mrs. John Bradley (Florence Briggs Thayer)\",\"Sex\":\"female\",\"Age\":38.0,\"SibSp\":1,\"Parch\":0,\"Ticket\":\"PC 17599\",\"Fare\":71.2833,\"Cabin\":\"C85\",\"Embarked\":\"C\"},{\"PassengerId\":3,\"Survived\":1,\"Pclass\":3,\"Name\":\"Heikkinen, Miss. Laina\",\"Sex\":\"female\",\"Age\":26.0,\"SibSp\":0,\"Parch\":0,\"Ticket\":\"STON\\\\/O2. 3101282\",\"Fare\":7.925,\"Cabin\":null,\"Embarked\":\"S\"},{\"PassengerId\":4,\"Survived\":1,\"Pclass\":1,\"Name\":\"Futrelle, Mrs. Jacques Heath (Lily May Peel)\",\"Sex\":\"female\",\"Age\":35.0,\"SibSp\":1,\"Parch\":0,\"Ticket\":\"113803\",\"Fare\":53.1,\"Cabin\":\"C123\",\"Embarked\":\"S\"},{\"PassengerId\":5,\"Survived\":0,\"Pclass\":3,\"Name\":\"Allen, Mr. William Henry\",\"Sex\":\"male\",\"Age\":35.0,\"SibSp\":0,\"Parch\":0,\"Ticket\":\"373450\",\"Fare\":8.05,\"Cabin\":null,\"Embarked\":\"S\"}]'"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# 2. APIs"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "- What's an API? (and why do we care?)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.a A simple web request"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib\n",
      "\n",
      "def get_historical_prices(symbol, start_date, end_date):\n",
      "    \"\"\"\n",
      "    Get historical prices for the given ticker symbol.\n",
      "    Date format is 'YYYYMMDD'\n",
      "    \n",
      "    Returns a json list.\n",
      "    \"\"\"\n",
      "    url = 'http://ichart.yahoo.com/table.csv?s=%s&' % symbol + \\\n",
      "          'd=%s&' % str(int(end_date[4:6]) - 1) + \\\n",
      "          'e=%s&' % str(int(end_date[6:8])) + \\\n",
      "          'f=%s&' % str(int(end_date[0:4])) + \\\n",
      "          'g=d&' + \\\n",
      "          'a=%s&' % str(int(start_date[4:6]) - 1) + \\\n",
      "          'b=%s&' % str(int(start_date[6:8])) + \\\n",
      "          'c=%s&' % str(int(start_date[0:4])) + \\\n",
      "          'ignore=.csv'\n",
      "    days = urllib.urlopen(url).readlines()\n",
      "    data = [day[:-2].split(',') for day in days]\n",
      "    return data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "get_historical_prices('GOOGL', '20140101', '20140106')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "[['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Clos'],\n",
        " ['2014-01-06',\n",
        "  '1113.01',\n",
        "  '1118.86',\n",
        "  '1106.44',\n",
        "  '1117.32',\n",
        "  '3535000',\n",
        "  '559.2'],\n",
        " ['2014-01-03',\n",
        "  '1115.00',\n",
        "  '1116.93',\n",
        "  '1104.93',\n",
        "  '1105.00',\n",
        "  '3330000',\n",
        "  '553.0'],\n",
        " ['2014-01-02',\n",
        "  '1115.46',\n",
        "  '1117.75',\n",
        "  '1108.26',\n",
        "  '1113.12',\n",
        "  '3639100',\n",
        "  '557.1']]"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# obtain the prices of Yahoo for the past month and insert them in a Pandas Dataframe\n",
      "\n",
      "prices =get_historical_prices('YHOO', '20140217', '20140317')\n",
      "\n",
      "df = pd.DataFrame(prices[1:], columns= prices[0], dtype=int).set_index('Date')\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Open</th>\n",
        "      <th>High</th>\n",
        "      <th>Low</th>\n",
        "      <th>Close</th>\n",
        "      <th>Volume</th>\n",
        "      <th>Adj Clos</th>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Date</th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2014-03-17</th>\n",
        "      <td> 39.00</td>\n",
        "      <td> 39.36</td>\n",
        "      <td> 38.61</td>\n",
        "      <td> 39.11</td>\n",
        "      <td> 29698300</td>\n",
        "      <td> 39.1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-03-14</th>\n",
        "      <td> 36.69</td>\n",
        "      <td> 38.19</td>\n",
        "      <td> 36.45</td>\n",
        "      <td> 37.60</td>\n",
        "      <td> 30862300</td>\n",
        "      <td> 37.6</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-03-13</th>\n",
        "      <td> 38.05</td>\n",
        "      <td> 38.42</td>\n",
        "      <td> 36.81</td>\n",
        "      <td> 37.23</td>\n",
        "      <td> 21179700</td>\n",
        "      <td> 37.2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-03-12</th>\n",
        "      <td> 37.21</td>\n",
        "      <td> 37.61</td>\n",
        "      <td> 36.48</td>\n",
        "      <td> 37.50</td>\n",
        "      <td> 14794700</td>\n",
        "      <td> 37.5</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2014-03-11</th>\n",
        "      <td> 38.25</td>\n",
        "      <td> 38.30</td>\n",
        "      <td> 37.43</td>\n",
        "      <td> 37.56</td>\n",
        "      <td> 12592300</td>\n",
        "      <td> 37.5</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "             Open   High    Low  Close    Volume Adj Clos\n",
        "Date                                                     \n",
        "2014-03-17  39.00  39.36  38.61  39.11  29698300     39.1\n",
        "2014-03-14  36.69  38.19  36.45  37.60  30862300     37.6\n",
        "2014-03-13  38.05  38.42  36.81  37.23  21179700     37.2\n",
        "2014-03-12  37.21  37.61  36.48  37.50  14794700     37.5\n",
        "2014-03-11  38.25  38.30  37.43  37.56  12592300     37.5"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df.info()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "Index: 20 entries, 2014-03-17 to 2014-02-18\n",
        "Data columns (total 6 columns):\n",
        "Open        20 non-null object\n",
        "High        20 non-null object\n",
        "Low         20 non-null object\n",
        "Close       20 non-null object\n",
        "Volume      20 non-null int64\n",
        "Adj Clos    20 non-null object\n",
        "dtypes: int64(1), object(5)"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 1\n",
      "##### Create a pandas dataframe with all the stock price data for Alibaba (BABA)\n",
      "##### What was the highest trading price of the Alibaba stock?\n",
      "##### What was the lowest trading price of the Alibaba stock?\n",
      "\n",
      "#### Hint: Look in pandas documentation or stackoverflow\n",
      "\n",
      "### Bonus Question\n",
      "##### What were the Yahoo highs and lows for the same days as the Alibaba highs and lows?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2.b Unstructured data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "#### HTTP requests can be handled easily using Python's `requests` library.\n",
      "\n",
      "First we will load our credentials which we keep in a [YAML](http://www.yaml.org/) file for safe keeping."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import yaml\n",
      "credentials = yaml.load(open('/users/Craig_Sakuma/api_cred.yml'))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Then we pass those credentials in to a GET request using the requests library. In this case, I am querying my own user data from Github:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import requests\n",
      "r = requests.get('https://api.github.com/user', \n",
      "                 auth=(credentials['USER'], credentials['PASS']))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "source": [
      "Requests gives us an object from which we can read its content."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r.content"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "'{\"login\":\"craigsakuma\",\"id\":4754768,\"avatar_url\":\"https://avatars.githubusercontent.com/u/4754768?v=2\",\"gravatar_id\":\"\",\"url\":\"https://api.github.com/users/craigsakuma\",\"html_url\":\"https://github.com/craigsakuma\",\"followers_url\":\"https://api.github.com/users/craigsakuma/followers\",\"following_url\":\"https://api.github.com/users/craigsakuma/following{/other_user}\",\"gists_url\":\"https://api.github.com/users/craigsakuma/gists{/gist_id}\",\"starred_url\":\"https://api.github.com/users/craigsakuma/starred{/owner}{/repo}\",\"subscriptions_url\":\"https://api.github.com/users/craigsakuma/subscriptions\",\"organizations_url\":\"https://api.github.com/users/craigsakuma/orgs\",\"repos_url\":\"https://api.github.com/users/craigsakuma/repos\",\"events_url\":\"https://api.github.com/users/craigsakuma/events{/privacy}\",\"received_events_url\":\"https://api.github.com/users/craigsakuma/received_events\",\"type\":\"User\",\"site_admin\":false,\"public_repos\":3,\"public_gists\":0,\"followers\":1,\"following\":3,\"created_at\":\"2013-06-21T01:32:11Z\",\"updated_at\":\"2014-10-06T16:10:58Z\",\"private_gists\":0,\"total_private_repos\":0,\"owned_private_repos\":0,\"disk_usage\":88748,\"collaborators\":0,\"plan\":{\"name\":\"free\",\"space\":307200,\"collaborators\":0,\"private_repos\":0}}'"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "#### One of the reasons we like JSON is that it is easy to transform into a Python `dict` object using the `json` library:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "user = json.loads(r.content)\n",
      "user"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "{u'avatar_url': u'https://avatars.githubusercontent.com/u/4754768?v=2',\n",
        " u'collaborators': 0,\n",
        " u'created_at': u'2013-06-21T01:32:11Z',\n",
        " u'disk_usage': 88748,\n",
        " u'events_url': u'https://api.github.com/users/craigsakuma/events{/privacy}',\n",
        " u'followers': 1,\n",
        " u'followers_url': u'https://api.github.com/users/craigsakuma/followers',\n",
        " u'following': 3,\n",
        " u'following_url': u'https://api.github.com/users/craigsakuma/following{/other_user}',\n",
        " u'gists_url': u'https://api.github.com/users/craigsakuma/gists{/gist_id}',\n",
        " u'gravatar_id': u'',\n",
        " u'html_url': u'https://github.com/craigsakuma',\n",
        " u'id': 4754768,\n",
        " u'login': u'craigsakuma',\n",
        " u'organizations_url': u'https://api.github.com/users/craigsakuma/orgs',\n",
        " u'owned_private_repos': 0,\n",
        " u'plan': {u'collaborators': 0,\n",
        "  u'name': u'free',\n",
        "  u'private_repos': 0,\n",
        "  u'space': 307200},\n",
        " u'private_gists': 0,\n",
        " u'public_gists': 0,\n",
        " u'public_repos': 3,\n",
        " u'received_events_url': u'https://api.github.com/users/craigsakuma/received_events',\n",
        " u'repos_url': u'https://api.github.com/users/craigsakuma/repos',\n",
        " u'site_admin': False,\n",
        " u'starred_url': u'https://api.github.com/users/craigsakuma/starred{/owner}{/repo}',\n",
        " u'subscriptions_url': u'https://api.github.com/users/craigsakuma/subscriptions',\n",
        " u'total_private_repos': 0,\n",
        " u'type': u'User',\n",
        " u'updated_at': u'2014-10-06T16:10:58Z',\n",
        " u'url': u'https://api.github.com/users/craigsakuma'}"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print user.keys()"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[u'disk_usage', u'private_gists', u'site_admin', u'subscriptions_url', u'gravatar_id', u'id', u'followers_url', u'following_url', u'collaborators', u'total_private_repos', u'followers', u'type', u'public_repos', u'gists_url', u'owned_private_repos', u'events_url', u'html_url', u'updated_at', u'plan', u'received_events_url', u'starred_url', u'public_gists', u'organizations_url', u'url', u'created_at', u'avatar_url', u'repos_url', u'following', u'login']\n"
       ]
      }
     ],
     "prompt_number": 112
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "subslide"
      }
     },
     "source": [
      "We can access values in this dict directly (such as my hireable status) and even render the url of my avatar:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "print \"Hireable: {}\".format(user.get('hireable'))\n",
      "HTML('<img src={} />'.format(user.get('avatar_url')))"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Hireable: None\n"
       ]
      },
      {
       "html": [
        "<img src=https://avatars.githubusercontent.com/u/4754768?v=2 />"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 113,
       "text": [
        "<IPython.core.display.HTML at 0x10a946810>"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Twitter API"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Twitter has no less than 10 python libraries. We'll be using Python Twitter Tools because it's what's used in Mining the Social Web."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "source": [
      "#### Some services (like Twitter) have released Python libraries of their own to make using their API even easier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter\n",
      "\n",
      "auth = twitter.oauth.OAuth(credentials['OAUTH_TOKEN'], \n",
      "                           credentials['OAUTH_TOKEN_SECRET'],\n",
      "                           credentials['CONSUMER_KEY'],\n",
      "                           credentials['CONSUMER_SECRET'])\n",
      "\n",
      "twitter_api = twitter.Twitter(auth=auth)\n",
      "\n",
      "print twitter_api"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<twitter.api.Twitter object at 0x10a946950>\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "skip"
      }
     },
     "source": [
      "#### Using a library like this, we don't even need to specify the URL (that's handled internally)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Using a library like this, it's easy to do something like search for tweets mentioning `#bigdata`  \n",
      "\n",
      "The results are transformed into a Python object (which in this case is a thin wrapper around a `dict`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigdata = twitter_api.search.tweets(q='#bigdata', count=5)\n",
      "type(bigdata)"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 115,
       "text": [
        "twitter.api.TwitterDictResponse"
       ]
      }
     ],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for status in bigdata['statuses']:\n",
      "    print status.get('text')"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "fragment"
      }
     },
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RT @FaceOfBigData: FAU Gets Grant to Step Into the Big Leagues of #BigData http://t.co/8FJUdKa4dP\n",
        "The Future of Big #Data Analysis by @DataBricks | @BigDataExpo [#BigData] | #Cloud Computing Journal http://t.co/AlHJkAmL08\n",
        "Big data and cloud computing look for bigger foothold in enterprises: http://t.co/jgFFSk7jDI  #bigdata #cloud\n",
        "Great Essay from Edward Tufte, the Galileo of Graphics. Stay tuned for our 1st blog post coming soon! #bigdata http://t.co/f6FB5epAmg\n",
        "Blogpost: Discovering what happens in the media without reading an article #media #bigdata http://t.co/gguBqeIIrY\n"
       ]
      }
     ],
     "prompt_number": 116
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Twitter lab\n",
      "[http://tinyurl.com/GAtwitterlab](http://nbviewer.ipython.org/github/ptwobrussell/Mining-the-Social-Web-2nd-Edition/blob/master/ipynb/Chapter%201%20-%20Mining%20Twitter.ipynb) up through Exercise 5"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Useful links:\n",
      "\n",
      "[Mining the Social Web](https://github.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!pip install twitter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Requirement already satisfied (use --upgrade to upgrade): twitter in /Users/Craig_Sakuma/anaconda/lib/python2.7/site-packages\r\n",
        "Cleaning up...\r\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import twitter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Create your own Twitter credentials:\n",
      "\n",
      "#### Step 1:\n",
      "Go to https://dev.twitter.com/apps and sign in.\n",
      "\n",
      "#### Step 2:\n",
      "Register an application (doesn't have to be real, just a placeholder)\n",
      "\n",
      "Website: http://example.com\n",
      "\n",
      "Callback URL: http://example.com/auth/twitter/callback/\n",
      "\n",
      "#### Step 3:\n",
      "Add api key and api secret to your yaml file\n",
      "\n",
      "#### Step 4:\n",
      "Click on generate token and add information into your yaml file\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Create your own yaml file called api_cred.yml \n",
      "Use the credential_example.yml file as a template"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "credentials = yaml.load(open('/users/Craig_Sakuma/api_cred.yml'))\n",
      "auth = twitter.oauth.OAuth(credentials['OAUTH_TOKEN'], \n",
      "                           credentials['OAUTH_TOKEN_SECRET'],\n",
      "                           credentials['CONSUMER_KEY'],\n",
      "                           credentials['CONSUMER_SECRET'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twitter_api = twitter.Twitter(auth=auth)\n",
      "\n",
      "# Nothing to see by displaying twitter_api except that it's now a\n",
      "# defined variable\n",
      "\n",
      "print twitter_api"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<twitter.api.Twitter object at 0x10a95f850>\n"
       ]
      }
     ],
     "prompt_number": 120
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The Yahoo! Where On Earth ID for the entire world is 1.\n",
      "# See https://dev.twitter.com/docs/api/1.1/get/trends/place and\n",
      "# http://developer.yahoo.com/geo/geoplanet/\n",
      "\n",
      "WORLD_WOE_ID = 1\n",
      "US_WOE_ID = 23424977\n",
      "\n",
      "# Prefix ID with the underscore for query string parameterization.\n",
      "# Without the underscore, the twitter package appends the ID value\n",
      "# to the URL itself as a special case keyword argument.\n",
      "\n",
      "world_trends = twitter_api.trends.place(_id=WORLD_WOE_ID)\n",
      "us_trends = twitter_api.trends.place(_id=US_WOE_ID)\n",
      "\n",
      "print world_trends\n",
      "print\n",
      "print us_trends"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{u'created_at': u'2014-10-06T15:57:32Z', u'trends': [{u'url': u'http://twitter.com/search?q=%23HappyBirthLay', u'query': u'%23HappyBirthLay', u'name': u'#HappyBirthLay', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23MalemTwitter_NikiPP', u'query': u'%23MalemTwitter_NikiPP', u'name': u'#MalemTwitter_NikiPP', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23NombresLindos', u'query': u'%23NombresLindos', u'name': u'#NombresLindos', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23SmileForBam', u'query': u'%23SmileForBam', u'name': u'#SmileForBam', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23AhKe%C5%9FkeDemeyin', u'query': u'%23AhKe%C5%9FkeDemeyin', u'name': u'#AhKe\\u015fkeDemeyin', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%22Blake+Lively+and+Ryan+Reynolds%22', u'query': u'%22Blake+Lively+and+Ryan+Reynolds%22', u'name': u'Blake Lively and Ryan Reynolds', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%22Twin+Peaks%22', u'query': u'%22Twin+Peaks%22', u'name': u'Twin Peaks', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=Effy', u'query': u'Effy', u'name': u'Effy', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%22Iklan+TTI+082288113332+Lebih%22', u'query': u'%22Iklan+TTI+082288113332+Lebih%22', u'name': u'Iklan TTI 082288113332 Lebih', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=Orochimaru', u'query': u'Orochimaru', u'name': u'Orochimaru', u'promoted_content': None}], u'as_of': u'2014-10-06T16:01:37Z', u'locations': [{u'woeid': 1, u'name': u'Worldwide'}]}]\n",
        "\n",
        "[{u'created_at': u'2014-10-06T15:57:32Z', u'trends': [{u'url': u'http://twitter.com/search?q=%22Blake+Lively+Is+Pregnant%22', u'query': u'%22Blake+Lively+Is+Pregnant%22', u'name': u'Blake Lively Is Pregnant', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=Effy', u'query': u'Effy', u'name': u'Effy', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%22Twin+Peaks%22', u'query': u'%22Twin+Peaks%22', u'name': u'Twin Peaks', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23HappyBirthLay', u'query': u'%23HappyBirthLay', u'name': u'#HappyBirthLay', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23ZaynAndPerrieAreMarried', u'query': u'%23ZaynAndPerrieAreMarried', u'name': u'#ZaynAndPerrieAreMarried', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23Guess1DsOpeningActForOTRAT', u'query': u'%23Guess1DsOpeningActForOTRAT', u'name': u'#Guess1DsOpeningActForOTRAT', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23MOTOUGHMONDAY', u'query': u'%23MOTOUGHMONDAY', u'name': u'#MOTOUGHMONDAY', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%22Raven+Symone%22', u'query': u'%22Raven+Symone%22', u'name': u'Raven Symone', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=%23bbcon', u'query': u'%23bbcon', u'name': u'#bbcon', u'promoted_content': None}, {u'url': u'http://twitter.com/search?q=Muschamp', u'query': u'Muschamp', u'name': u'Muschamp', u'promoted_content': None}], u'as_of': u'2014-10-06T16:01:38Z', u'locations': [{u'woeid': 23424977, u'name': u'United States'}]}]\n"
       ]
      }
     ],
     "prompt_number": 121
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "\n",
      "print json.dumps(world_trends, indent=1)\n",
      "print\n",
      "print json.dumps(us_trends, indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[\n",
        " {\n",
        "  \"created_at\": \"2014-10-06T15:57:32Z\", \n",
        "  \"trends\": [\n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23HappyBirthLay\", \n",
        "    \"query\": \"%23HappyBirthLay\", \n",
        "    \"name\": \"#HappyBirthLay\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23MalemTwitter_NikiPP\", \n",
        "    \"query\": \"%23MalemTwitter_NikiPP\", \n",
        "    \"name\": \"#MalemTwitter_NikiPP\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23NombresLindos\", \n",
        "    \"query\": \"%23NombresLindos\", \n",
        "    \"name\": \"#NombresLindos\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23SmileForBam\", \n",
        "    \"query\": \"%23SmileForBam\", \n",
        "    \"name\": \"#SmileForBam\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23AhKe%C5%9FkeDemeyin\", \n",
        "    \"query\": \"%23AhKe%C5%9FkeDemeyin\", \n",
        "    \"name\": \"#AhKe\\u015fkeDemeyin\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%22Blake+Lively+and+Ryan+Reynolds%22\", \n",
        "    \"query\": \"%22Blake+Lively+and+Ryan+Reynolds%22\", \n",
        "    \"name\": \"Blake Lively and Ryan Reynolds\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%22Twin+Peaks%22\", \n",
        "    \"query\": \"%22Twin+Peaks%22\", \n",
        "    \"name\": \"Twin Peaks\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=Effy\", \n",
        "    \"query\": \"Effy\", \n",
        "    \"name\": \"Effy\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%22Iklan+TTI+082288113332+Lebih%22\", \n",
        "    \"query\": \"%22Iklan+TTI+082288113332+Lebih%22\", \n",
        "    \"name\": \"Iklan TTI 082288113332 Lebih\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=Orochimaru\", \n",
        "    \"query\": \"Orochimaru\", \n",
        "    \"name\": \"Orochimaru\", \n",
        "    \"promoted_content\": null\n",
        "   }\n",
        "  ], \n",
        "  \"as_of\": \"2014-10-06T16:01:37Z\", \n",
        "  \"locations\": [\n",
        "   {\n",
        "    \"woeid\": 1, \n",
        "    \"name\": \"Worldwide\"\n",
        "   }\n",
        "  ]\n",
        " }\n",
        "]\n",
        "\n",
        "[\n",
        " {\n",
        "  \"created_at\": \"2014-10-06T15:57:32Z\", \n",
        "  \"trends\": [\n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%22Blake+Lively+Is+Pregnant%22\", \n",
        "    \"query\": \"%22Blake+Lively+Is+Pregnant%22\", \n",
        "    \"name\": \"Blake Lively Is Pregnant\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=Effy\", \n",
        "    \"query\": \"Effy\", \n",
        "    \"name\": \"Effy\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%22Twin+Peaks%22\", \n",
        "    \"query\": \"%22Twin+Peaks%22\", \n",
        "    \"name\": \"Twin Peaks\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23HappyBirthLay\", \n",
        "    \"query\": \"%23HappyBirthLay\", \n",
        "    \"name\": \"#HappyBirthLay\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23ZaynAndPerrieAreMarried\", \n",
        "    \"query\": \"%23ZaynAndPerrieAreMarried\", \n",
        "    \"name\": \"#ZaynAndPerrieAreMarried\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23Guess1DsOpeningActForOTRAT\", \n",
        "    \"query\": \"%23Guess1DsOpeningActForOTRAT\", \n",
        "    \"name\": \"#Guess1DsOpeningActForOTRAT\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23MOTOUGHMONDAY\", \n",
        "    \"query\": \"%23MOTOUGHMONDAY\", \n",
        "    \"name\": \"#MOTOUGHMONDAY\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%22Raven+Symone%22\", \n",
        "    \"query\": \"%22Raven+Symone%22\", \n",
        "    \"name\": \"Raven Symone\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=%23bbcon\", \n",
        "    \"query\": \"%23bbcon\", \n",
        "    \"name\": \"#bbcon\", \n",
        "    \"promoted_content\": null\n",
        "   }, \n",
        "   {\n",
        "    \"url\": \"http://twitter.com/search?q=Muschamp\", \n",
        "    \"query\": \"Muschamp\", \n",
        "    \"name\": \"Muschamp\", \n",
        "    \"promoted_content\": null\n",
        "   }\n",
        "  ], \n",
        "  \"as_of\": \"2014-10-06T16:01:38Z\", \n",
        "  \"locations\": [\n",
        "   {\n",
        "    \"woeid\": 23424977, \n",
        "    \"name\": \"United States\"\n",
        "   }\n",
        "  ]\n",
        " }\n",
        "]\n"
       ]
      }
     ],
     "prompt_number": 122
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "world_trends_set = set([trend['name'] \n",
      "                        for trend in world_trends[0]['trends']])\n",
      "\n",
      "us_trends_set = set([trend['name'] \n",
      "                     for trend in us_trends[0]['trends']]) \n",
      "\n",
      "common_trends = world_trends_set.intersection(us_trends_set)\n",
      "\n",
      "print common_trends"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "set([u'#HappyBirthLay', u'Twin Peaks', u'Effy'])\n"
       ]
      }
     ],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "q = '#DataScience' \n",
      "\n",
      "count = 100\n",
      "\n",
      "# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\n",
      "\n",
      "search_results = twitter_api.search.tweets(q=q, count=count)\n",
      "\n",
      "statuses = search_results['statuses']\n",
      "\n",
      "# print json.dumps(search_results, indent=1)\n",
      "print json.dumps(statuses, indent=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'twitter_api' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-3-7e70aa6c9450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# See https://dev.twitter.com/docs/api/1.1/get/search/tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msearch_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtwitter_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mstatuses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'statuses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'twitter_api' is not defined"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "status_texts = [ status['text'] \n",
      "                 for status in statuses ]\n",
      "\n",
      "screen_names = [ user_mention['screen_name'] \n",
      "                 for status in statuses\n",
      "                     for user_mention in status['entities']['user_mentions'] ]\n",
      "\n",
      "hashtags = [ hashtag['text'] \n",
      "             for status in statuses\n",
      "                 for hashtag in status['entities']['hashtags'] ]\n",
      "\n",
      "# Compute a collection of all words from all tweets\n",
      "words = [ w \n",
      "          for t in status_texts \n",
      "              for w in t.split() ]\n",
      "\n",
      "# Explore the first 5 items for each...\n",
      "\n",
      "print json.dumps(status_texts[0:5], indent=1)\n",
      "print json.dumps(screen_names[0:5], indent=1) \n",
      "print json.dumps(hashtags[0:5], indent=1)\n",
      "print json.dumps(words[0:5], indent=1)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[\n",
        " \"Bringing Data Science to K-12 Students: http://t.co/ncH7cVb0AT #datascience #bigdata\", \n",
        " \"7 Step Life Cycle of #DataScience Projects http://t.co/Q6KABbg8Kd\", \n",
        " \"RT @GilPress: Top Ten Most Funded Big Data Startups October 2014 http://t.co/E65MNxTCnu via @forbes #DataScience #MachineLearning #Hadoop\", \n",
        " \"New Job Posted: Senior Data Scientist - Zynga http://t.co/Io96DgHW72 #AnalyticTalent #DataScience #AnalyticJobs\", \n",
        " \"RT @GilPress: Top Ten Most Funded Big Data Startups October 2014 http://t.co/E65MNxTCnu via @forbes #DataScience #MachineLearning #Hadoop\"\n",
        "]\n",
        "[\n",
        " \"GilPress\", \n",
        " \"Forbes\", \n",
        " \"GilPress\", \n",
        " \"Forbes\", \n",
        " \"GilPress\"\n",
        "]\n",
        "[\n",
        " \"datascience\", \n",
        " \"bigdata\", \n",
        " \"DataScience\", \n",
        " \"DataScience\", \n",
        " \"MachineLearning\"\n",
        "]\n",
        "[\n",
        " \"Bringing\", \n",
        " \"Data\", \n",
        " \"Science\", \n",
        " \"to\", \n",
        " \"K-12\"\n",
        "]\n"
       ]
      }
     ],
     "prompt_number": 125
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter\n",
      "\n",
      "for item in [words, screen_names, hashtags]:\n",
      "    c = Counter(item)\n",
      "    print c.most_common()[:10] # top 10\n",
      "    print\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(u'#DataScience', 58), (u'RT', 42), (u'#datascience', 28), (u'#BigData', 26), (u'to', 23), (u'the', 23), (u'Data', 22), (u'and', 15), (u'#bigdata', 15), (u'in', 15)]\n",
        "\n",
        "[(u'Polytechnique', 10), (u'Forbes', 8), (u'GilPress', 6), (u'stevndmills', 4), (u'eBay', 4), (u'Terry_Timko', 4), (u'mark_torr', 4), (u'Doug_Laney', 3), (u'DistrictDataLab', 3), (u'tonyojeda3', 2)]\n",
        "\n",
        "[(u'DataScience', 67), (u'datascience', 31), (u'BigData', 26), (u'bigdata', 15), (u'Hadoop', 9), (u'IoT', 9), (u'analytics', 8), (u'Program', 5), (u'Starter', 5), (u'MachineLearning', 5)]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Exercise 2\n",
      "##### What are the search results for #machinelearning?\n",
      "##### Which words, screen_names and hashtags are most common?\n",
      "\n",
      "### Bonus Questions\n",
      "##### Which hashtags are most common between #machinelearning and #datascience?\n",
      "##### Search the most popular data science hashtags and determine what topics are trending the most across the most popular data science hastags?\n",
      "##### Determine the most prolific screen_names for data science and find out who they are?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}